{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d078d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"룰 기반 공행성 탐색 + LightGBM 회귀 예측 파이프라인 (v3).\n",
    "\n",
    "1. train_month.csv를 월별 value 합계 pivot으로 변환\n",
    "2. 피어슨 상관계수 규칙으로 (leader, follower) 공행성 쌍 탐색\n",
    "3. follower/leader lag, diff, ratio 등 피처 생성 후 LightGBM 회귀 학습\n",
    "4. 2025-08을 대상으로 pair별 value 예측\n",
    "5. submission_{tag}_{오늘날짜}.csv 저장\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8fe8e8",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "0. 데이터 적재 및 월별 pivot 생성\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "638700a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_monthly_data(path: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"train_month.csv를 읽어 item_id × ym pivot 생성.\"\"\"\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"ym\"] = pd.to_datetime(dict(year=df[\"year\"], month=df[\"month\"], day=1))\n",
    "\n",
    "    monthly = (\n",
    "        df.groupby([\"item_id\", \"ym\"], as_index=False)[\"value\"]\n",
    "        .sum()\n",
    "        .rename(columns={\"value\": \"value_sum\"})\n",
    "    )\n",
    "    pivot = (\n",
    "        monthly.pivot_table(index=\"ym\", columns=\"item_id\", values=\"value_sum\", aggfunc=\"sum\")\n",
    "        .sort_index()\n",
    "        .fillna(0.0)\n",
    "    )\n",
    "    return monthly, pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc0f3ed",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "1. 공행성 쌍 탐색 (룰 기반)\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b44756fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_corr(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"분산=0 예외를 처리한 피어슨 상관계수.\"\"\"\n",
    "\n",
    "    if x.std() == 0 or y.std() == 0:\n",
    "        return 0.0\n",
    "    return float(np.corrcoef(x, y)[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e58c8ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_comovement_pairs(\n",
    "    pivot: pd.DataFrame,\n",
    "    max_lag: int = 6,\n",
    "    min_nonzero: int = 12,\n",
    "    corr_threshold: float = 0.4,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"피어슨 룰 기반으로 (leader, follower) 공행성 쌍 탐색.\"\"\"\n",
    "\n",
    "    items = pivot.columns.tolist()\n",
    "    pairs: List[Dict[str, float]] = []\n",
    "\n",
    "    for leader in items:\n",
    "        leader_series = pivot[leader].values.astype(float)\n",
    "        if np.count_nonzero(leader_series) < min_nonzero:\n",
    "            continue\n",
    "        for follower in items:\n",
    "            if leader == follower:\n",
    "                continue\n",
    "            follower_series = pivot[follower].values.astype(float)\n",
    "            if np.count_nonzero(follower_series) < min_nonzero:\n",
    "                continue\n",
    "\n",
    "            best_lag = None\n",
    "            best_corr = 0.0\n",
    "            for lag in range(1, max_lag + 1):\n",
    "                if len(leader_series) <= lag:\n",
    "                    break\n",
    "                x = leader_series[:-lag]\n",
    "                y = follower_series[lag:]\n",
    "                corr = safe_corr(x, y)\n",
    "                if abs(corr) > abs(best_corr):\n",
    "                    best_corr = corr\n",
    "                    best_lag = lag\n",
    "\n",
    "            if best_lag is None or abs(best_corr) < corr_threshold:\n",
    "                continue\n",
    "\n",
    "            pairs.append(\n",
    "                {\n",
    "                    \"leading_item_id\": leader,\n",
    "                    \"following_item_id\": follower,\n",
    "                    \"best_lag\": int(best_lag),\n",
    "                    \"max_corr\": float(best_corr),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a0ca0",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "2. 회귀용 학습 데이터 구성\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eccb4d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_pair_frame(\n",
    "    pivot: pd.DataFrame,\n",
    "    leader: str,\n",
    "    follower: str,\n",
    "    best_lag: int,\n",
    "    max_corr: float,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"단일 pair에 대한 시점별 피처 계산.\"\"\"\n",
    "\n",
    "    leader_series = pivot[leader]\n",
    "    follower_series = pivot[follower]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"date\": pivot.index,\n",
    "        \"b_t\": follower_series.values,\n",
    "    })\n",
    "    df[\"b_t_1\"] = df[\"b_t\"].shift(1)\n",
    "    df[\"b_t_2\"] = df[\"b_t\"].shift(2)\n",
    "\n",
    "    df[\"b_diff1\"] = df[\"b_t\"] - df[\"b_t_1\"]\n",
    "    df[\"b_diff2\"] = df[\"b_t\"] - df[\"b_t_2\"]\n",
    "    df[\"b_pct1\"] = (df[\"b_t\"] - df[\"b_t_1\"]) / (df[\"b_t_1\"].replace(0, np.nan) + 1e-6)\n",
    "    df[\"b_pct2\"] = (df[\"b_t\"] - df[\"b_t_2\"]) / (df[\"b_t_2\"].replace(0, np.nan) + 1e-6)\n",
    "    df[\"b_roll3\"] = follower_series.rolling(window=3, min_periods=3).mean().values\n",
    "    df[\"b_std3\"] = follower_series.rolling(window=3, min_periods=3).std().values\n",
    "    df[\"b_expanding_mean\"] = follower_series.expanding(min_periods=3).mean().values\n",
    "    df[\"b_zscore3\"] = (df[\"b_t\"] - df[\"b_roll3\"]) / (df[\"b_std3\"] + 1e-8)\n",
    "\n",
    "    # 타깃 등\n",
    "    df[\"target_value\"] = df[\"b_t\"].shift(-1)\n",
    "    df[\"target_log1p\"] = np.log1p(df[\"target_value\"].clip(lower=0))\n",
    "    df[\"target_date\"] = df[\"date\"] + pd.offsets.MonthBegin(1)\n",
    "\n",
    "    # 메타 정보\n",
    "    df[\"leading_item_id\"] = leader\n",
    "    df[\"following_item_id\"] = follower\n",
    "    df[\"best_lag\"] = best_lag\n",
    "    df[\"max_corr\"] = max_corr\n",
    "\n",
    "    # 계절성\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "    df[\"quarter\"] = df[\"date\"].dt.quarter\n",
    "\n",
    "    required_cols = [\n",
    "        # follower 기준 값\n",
    "        \"b_t\",         # 현시점 값\n",
    "        \"b_t_1\",       # 1개월 전\n",
    "        \"b_t_2\",       # 2개월 전\n",
    "        \"b_roll3\",     # 최근 3개월 평균\n",
    "        \"b_diff1\",     # 1개월 변화량 (b_t - b_t_1)\n",
    "        \"b_diff2\",     # 2개월 변화량 (b_t - b_t_2)\n",
    "        \"b_pct1\",      # 직전 대비 증감율\n",
    "        \"b_pct2\",      # 2기 전 대비 증감율\n",
    "        \"b_std3\",      # 최근 3개월 표준편차\n",
    "        \"b_expanding_mean\", # 전체 누적 평균\n",
    "        \"b_zscore3\",   # 3개월 z-score\n",
    "\n",
    "        # leader 기준 값 (쌍/리더 특성)\n",
    "        \"a_t_lag\",     # 리더 item lag 특성\n",
    "        \"a_t_lag_1\",\n",
    "        \"a_diff_lag\",\n",
    "        \"a_pct_lag\",\n",
    "\n",
    "        # 계절성\n",
    "        \"month\",\n",
    "        \"quarter\",\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # 필요한 경우 b_t_3~5, b_roll6/12도 추가!\n",
    "\n",
    "    df = df.dropna(subset=[col for col in required_cols if col in df.columns])\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7890339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_training_data(pivot: pd.DataFrame, pairs: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"모든 pair에 대한 학습용 레코드 결합.\"\"\"\n",
    "\n",
    "    frames = []\n",
    "    for _, row in pairs.iterrows():\n",
    "        pair_frame = _build_pair_frame(\n",
    "            pivot,\n",
    "            leader=row[\"leading_item_id\"],\n",
    "            follower=row[\"following_item_id\"],\n",
    "            best_lag=row[\"best_lag\"],\n",
    "            max_corr=row[\"max_corr\"],\n",
    "        )\n",
    "        if not pair_frame.empty:\n",
    "            frames.append(pair_frame)\n",
    "\n",
    "    if not frames:\n",
    "        raise ValueError(\"학습 데이터가 생성되지 않았습니다.\")\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "    df = df[df[\"target_date\"].notna()]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aed7d2",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "3. LightGBM 회귀 모델 학습\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c83d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_gridsearch(X_train, y_train, X_valid, y_valid, param_grid):\n",
    "    best_results = []\n",
    "    best_rmse = float(\"inf\")\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    param_points = [\n",
    "        (lr, n_leaves, max_depth, reg_alpha, reg_lambda, boosting_type)\n",
    "        for lr in param_grid[\"learning_rate\"]\n",
    "        for n_leaves in param_grid[\"num_leaves\"]\n",
    "        for max_depth in param_grid[\"max_depth\"]\n",
    "        for reg_alpha in param_grid[\"reg_alpha\"]\n",
    "        for reg_lambda in param_grid[\"reg_lambda\"]\n",
    "        for boosting_type in param_grid[\"boosting_type\"]\n",
    "    ]\n",
    "\n",
    "    for lr, n_leaves, max_depth, reg_alpha, reg_lambda, boosting_type in tqdm(param_points, desc=\"LGBM GridSearch\"):\n",
    "        model = LGBMRegressor(\n",
    "            objective=\"regression\",\n",
    "            n_estimators=1000,\n",
    "            learning_rate=lr,\n",
    "            num_leaves=n_leaves,\n",
    "            max_depth=max_depth,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            verbosity=-1,\n",
    "            reg_alpha=reg_alpha,\n",
    "            reg_lambda=reg_lambda,\n",
    "            boosting_type=boosting_type\n",
    "        )\n",
    "        model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], eval_metric=\"l2\")\n",
    "        y_pred = model.predict(X_valid)\n",
    "        rmse = mean_squared_error(y_valid, y_pred) ** 0.5\n",
    "        best_results.append({\n",
    "            \"learning_rate\": lr,\n",
    "            \"num_leaves\": n_leaves,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"reg_alpha\": reg_alpha,\n",
    "            \"reg_lambda\": reg_lambda,\n",
    "            \"boosting_type\": boosting_type,\n",
    "            \"rmse\": rmse\n",
    "        })\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_params = {\n",
    "                \"learning_rate\": lr,\n",
    "                \"num_leaves\": n_leaves,\n",
    "                \"max_depth\": max_depth,\n",
    "                \"reg_alpha\": reg_alpha,\n",
    "                \"reg_lambda\": reg_lambda,\n",
    "                \"boosting_type\": boosting_type\n",
    "            }\n",
    "            best_model = model\n",
    "\n",
    "    # 상위 5개만 RMSE 기준 오름차순 정렬 후 출력\n",
    "    topn = 5\n",
    "    best_results = sorted(best_results, key=lambda x: x[\"rmse\"])\n",
    "    print(\"Top parameter sets:\")\n",
    "    for r in best_results[:topn]:\n",
    "        print(\n",
    "            f\"LR={r['learning_rate']}, Leaves={r['num_leaves']}, \"\n",
    "            f\"Depth={r['max_depth']}, Alpha={r['reg_alpha']}, \"\n",
    "            f\"Lambda={r['reg_lambda']}, Type={r['boosting_type']} | RMSE={r['rmse']:.6f}\"\n",
    "        )\n",
    "\n",
    "    print(f\"\\nBest Params: {best_params} | Best RMSE: {best_rmse:.6f}\")\n",
    "    return best_model, best_params, best_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16b15288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression_model(train_df: pd.DataFrame) -> Tuple[LGBMRegressor, List[str]]:\n",
    "    train_cutoff = pd.Timestamp(\"2024-12-01\")\n",
    "    valid_start = pd.Timestamp(\"2025-01-01\")\n",
    "    valid_end = pd.Timestamp(\"2025-05-01\")\n",
    "\n",
    "    drop_cols = {\"date\", \"target_date\", \"target_value\", \"target_log1p\", \"leading_item_id\", \"following_item_id\"}\n",
    "    feature_cols = [col for col in train_df.columns if col not in drop_cols]\n",
    "\n",
    "    train_mask = train_df[\"target_date\"] <= train_cutoff\n",
    "    valid_mask = (train_df[\"target_date\"] >= valid_start) & (train_df[\"target_date\"] <= valid_end)\n",
    "\n",
    "    if train_mask.sum() == 0 or valid_mask.sum() == 0:\n",
    "        raise ValueError(\"train/valid 기간 데이터가 부족합니다.\")\n",
    "\n",
    "    X_train = train_df.loc[train_mask, feature_cols]\n",
    "    y_train = train_df.loc[train_mask, \"target_log1p\"]\n",
    "    X_valid = train_df.loc[valid_mask, feature_cols]\n",
    "    y_valid = train_df.loc[valid_mask, \"target_log1p\"]\n",
    "\n",
    "    param_grid = {\n",
    "        \"learning_rate\": [0.12, 0.13, 0.14, 0.15],\n",
    "        \"num_leaves\": [111, 127, 143, 160],\n",
    "        \"max_depth\": [10, 12, 14],\n",
    "        \"reg_alpha\": [0, 0.1, 0.3],\n",
    "        \"reg_lambda\": [0, 0.1, 0.3],\n",
    "        \"boosting_type\": [\"gbdt\", \"dart\"]\n",
    "    }\n",
    "\n",
    "    best_model, best_params, best_rmse = lgbm_gridsearch(X_train, y_train, X_valid, y_valid, param_grid)\n",
    "    return best_model, feature_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc0695e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feature_importance(model, feature_cols, topn=20):\n",
    "    imp = model.feature_importances_\n",
    "    # 상위 N개만 보기\n",
    "    sorted_idx = np.argsort(imp)[::-1][:topn]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(np.array(feature_cols)[sorted_idx], imp[sorted_idx])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Top Feature Importances')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # 중요도 내림차순 순서의 feature 이름 리스트 반환(자동화 실험용)\n",
    "    return list(np.array(feature_cols)[sorted_idx])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879d9c4e",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "4. 예측 월 피처 생성\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db7dd411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inference_features(\n",
    "    pivot: pd.DataFrame,\n",
    "    pairs: pd.DataFrame,\n",
    "    forecast_month: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"forecast_month(예: 2025-08)에 대한 pair별 입력 피처 생성.\"\"\"\n",
    "\n",
    "    target_ts = pd.Timestamp(forecast_month + \"-01\")\n",
    "    base_ts = target_ts - pd.offsets.MonthBegin(1)\n",
    "    if base_ts not in pivot.index:\n",
    "        raise ValueError(f\"{base_ts.date()} 기준 데이터가 없습니다.\")\n",
    "\n",
    "    rows = []\n",
    "    for _, row in pairs.iterrows():\n",
    "        pair_frame = _build_pair_frame(\n",
    "            pivot,\n",
    "            leader=row[\"leading_item_id\"],\n",
    "            follower=row[\"following_item_id\"],\n",
    "            best_lag=row[\"best_lag\"],\n",
    "            max_corr=row[\"max_corr\"],\n",
    "        )\n",
    "        target_row = pair_frame[pair_frame[\"target_date\"] == target_ts]\n",
    "        if not target_row.empty:\n",
    "            rows.append(target_row.iloc[0].copy())\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6d5b72",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "5. 제출 파일 생성\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "724cfddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(\n",
    "    pairs: pd.DataFrame,\n",
    "    pred_df: pd.DataFrame,\n",
    "    pivot: pd.DataFrame,\n",
    "    best_params: dict,\n",
    "    feature_cols: List[str],\n",
    "    seeds: List[int] = [42, 77, 123, 314, 2718]  # 원하는 seed 리스트!\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"pair 목록에 예측 value를 결합하여 submission 생성.\"\"\"\n",
    "\n",
    "    submission = pairs[[\"leading_item_id\", \"following_item_id\"]].drop_duplicates().reset_index(drop=True)\n",
    "    latest_map = pivot.iloc[-1].to_dict()\n",
    "\n",
    "    if pred_df.empty:\n",
    "        submission[\"value\"] = submission[\"following_item_id\"].map(latest_map).fillna(0.0)\n",
    "    else:\n",
    "        X_test = pred_df[feature_cols].fillna(0.0)\n",
    "        all_preds = []\n",
    "        for seed in seeds:\n",
    "            model = LGBMRegressor(\n",
    "                learning_rate=best_params[\"learning_rate\"],\n",
    "                num_leaves=best_params[\"num_leaves\"],\n",
    "                max_depth=best_params[\"max_depth\"],\n",
    "                reg_alpha=best_params[\"reg_alpha\"],\n",
    "                reg_lambda=best_params[\"reg_lambda\"],\n",
    "                boosting_type=best_params[\"boosting_type\"],\n",
    "                random_state=seed,\n",
    "                n_estimators=1000,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                verbosity=-1,\n",
    "            )\n",
    "            # 일반적으로 X_train, y_train까지 인자로 받아서 .fit 재실행 필요\n",
    "            # 필요하다면, X_train, y_train을 추가로 넘겨주세요.\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred = np.maximum(0.0, np.expm1(y_pred))\n",
    "            all_preds.append(y_pred)\n",
    "        # 여러 seed 예측 결과 평균 적용\n",
    "        y_pred_ensemble = np.mean(all_preds, axis=0)\n",
    "\n",
    "        pred_values = pred_df[[\"leading_item_id\", \"following_item_id\"]].copy()\n",
    "        pred_values[\"value\"] = y_pred_ensemble\n",
    "\n",
    "        submission = submission.merge(\n",
    "            pred_values,\n",
    "            on=[\"leading_item_id\", \"following_item_id\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "        submission[\"value\"] = submission[\"value\"].fillna(\n",
    "            submission[\"following_item_id\"].map(latest_map)\n",
    "        )\n",
    "\n",
    "    submission[\"value\"] = submission[\"value\"].fillna(0.0)\n",
    "    submission[\"value\"] = submission[\"value\"].clip(lower=0).round().astype(int)\n",
    "    submission.drop_duplicates([\"leading_item_id\", \"following_item_id\"], inplace=True)\n",
    "    submission.reset_index(drop=True, inplace=True)\n",
    "    return submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9698003a",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "6. 메인 실행부 (sweep으로 교체)\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "644eca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_thresholds_and_select_topN(\n",
    "    pivot, \n",
    "    thresholds =  [0.38, 0.40, 0.41, 0.42, 0.43], \n",
    "    topN=3,\n",
    "    min_nonzero=15\n",
    "):\n",
    "    results = []\n",
    "    for th in thresholds:\n",
    "        try:\n",
    "            pairs = find_comovement_pairs(\n",
    "                pivot, max_lag=6, min_nonzero=min_nonzero, corr_threshold=th\n",
    "            )\n",
    "            print(f\"Threshold={th}: pairs={len(pairs)}\")\n",
    "            if pairs.empty:\n",
    "                print(f\"Threshold={th}: No pairs found, skipped\")\n",
    "                continue\n",
    "            train_df = build_training_data(pivot, pairs)\n",
    "            print(f\"Threshold={th}: train_df rows={len(train_df)}\")\n",
    "            model, feature_cols = train_regression_model(train_df)\n",
    "            \n",
    "            # Validation set 추출\n",
    "            valid_start = pd.Timestamp(\"2025-01-01\")\n",
    "            valid_end = pd.Timestamp(\"2025-05-01\")\n",
    "            valid_mask = (\n",
    "                (train_df[\"target_date\"] >= valid_start) & (train_df[\"target_date\"] <= valid_end)\n",
    "            )\n",
    "            X_valid = train_df.loc[valid_mask, feature_cols]\n",
    "            y_valid = train_df.loc[valid_mask, \"target_log1p\"]\n",
    "\n",
    "            # Validation Score (예: RMSE)\n",
    "            from sklearn.metrics import mean_squared_error\n",
    "            y_pred = model.predict(X_valid)\n",
    "            rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "\n",
    "            results.append({\n",
    "                'threshold': th,\n",
    "                'rmse': rmse,\n",
    "                'pair_count': len(pairs),\n",
    "                # 필요시 model, feature_cols 등 추가 저장\n",
    "            })\n",
    "\n",
    "            print(f\"Threshold={th:.3f} | pairs={len(pairs)} | Validation RMSE={rmse:.6f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Threshold={th:.3f}: {e}\")\n",
    "\n",
    "    # Top-N 성적 좋은 후보만 정렬 출력\n",
    "    results = sorted(results, key=lambda x: x['rmse'])\n",
    "    print(\"\\n--- Top N Validation Candidates ---\")\n",
    "    for i, r in enumerate(results[:topN]):\n",
    "        print(f\"Rank {i+1}: threshold={r['threshold']:.3f} | pairs={r['pair_count']} | RMSE={r['rmse']:.6f}\")\n",
    "    \n",
    "    return results[:topN]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11205e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pivot columns: Index(['AANGBULD', 'AHMDUILJ', 'ANWUJOKX', 'APQGTRMF', 'ATLDMDBO', 'AXULOHBQ',\n",
      "       'BEZYMBBT', 'BJALXPFS', 'BLANHGYY', 'BSRMSVTC', 'BTMOEMEP', 'BUZIIBYG',\n",
      "       'CCLHWFWF', 'DBWLZWNK', 'DDEXPPXU', 'DEWLVASR', 'DJBLNPNC', 'DNMPSKTB',\n",
      "       'DUCMGGNW', 'ELQGMQWE', 'EVBVXETX', 'FCYBOAXC', 'FDXPMYGF', 'FITUEHWN',\n",
      "       'FQCLOEXA', 'FRHNWLNI', 'FTSVTTSR', 'FWUCPMMW', 'GIKPEWTY', 'GKQIJYDH',\n",
      "       'GMBFCMIU', 'GYHKIVQT', 'HCDTGMST', 'HXYSSRXE', 'IGDVVKUD', 'JBVHSUWY',\n",
      "       'JERHKLYW', 'JPBRUTWP', 'JSLXRQOK', 'KAGJCHMR', 'KEUWZRKO', 'KFQSHBNH',\n",
      "       'KJNSOAHR', 'LLHREMKS', 'LPHPPJUG', 'LRVGFDFM', 'LSOIUSXD', 'LTOYKIML',\n",
      "       'LUENUFGA', 'MBSBZBXA', 'MIRCVAMV', 'NAQIHUKZ', 'NZKBIBNU', 'OGAFEHLU',\n",
      "       'OJIFIHMZ', 'OKMBFVKS', 'OXKURKXR', 'PLMZALFA', 'PYZMVUWD', 'QJQJSWFU',\n",
      "       'QKXNTIIB', 'QRKRBYJL', 'QSDCUCLB', 'QVLMOEYE', 'RAWUKQMJ', 'RCBZUSIM',\n",
      "       'RJCAXSGH', 'RJGPVEXX', 'ROACSLMG', 'RUVXNNVA', 'SAAYMURU', 'SAHWCZNH',\n",
      "       'SDWAYPIK', 'SNHYOVBM', 'STZDBITS', 'SUOYXCHP', 'TANNMIMB', 'TGOELCAG',\n",
      "       'UGEQLMXM', 'UIFPPCLR', 'UQYUIVVR', 'UXSPKBJR', 'VBYCLTYZ', 'VMAQSTJE',\n",
      "       'VUAFAIYJ', 'VWMBASNE', 'WBLJNPZQ', 'WHPUAOID', 'WPQXWHYO', 'WQMVCOEM',\n",
      "       'XIFHSOWQ', 'XIIEJNEE', 'XIPPENFQ', 'XMKRPGLB', 'XUOIQPFL', 'YSYHGLQK',\n",
      "       'ZCELVYQU', 'ZGJXVMNI', 'ZKENOUDA', 'ZXERAXWP'],\n",
      "      dtype='object', name='item_id')\n",
      "pivot shape: (43, 100)\n",
      "nonzero counts: [29, 43, 8, 42, 43, 43, 43, 43, 29, 43, 43, 43, 43, 43, 43, 42, 27, 43, 43, 43, 43, 43, 40, 43, 43, 43, 42, 30, 5, 43, 1, 43, 36, 43, 36, 43, 43, 43, 41, 39, 43, 7, 43, 43, 43, 43, 43, 43, 43, 43, 31, 26, 43, 29, 43, 43, 43, 3, 28, 43, 43, 43, 10, 43, 43, 43, 7, 43, 43, 3, 43, 43, 43, 43, 43, 37, 6, 28, 43, 43, 42, 43, 43, 43, 43, 43, 43, 42, 43, 42, 43, 28, 43, 43, 43, 39, 40, 43, 43, 43]\n",
      "Threshold=0.38: pairs=1702\n",
      "Threshold=0.38: train_df rows=63442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LGBM GridSearch:   9%|▊         | 75/864 [11:09<2:01:07,  9.21s/it]"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    data_path = \"train_month.csv\"\n",
    "    forecast_month = \"2025-08\"\n",
    "    thresholds = [0.38, 0.40, 0.41, 0.42, 0.43]  # 0.4~0.5 구간으로 올려서 실험!\n",
    "    topN = 3\n",
    "    min_nonzero = 15        \n",
    "\n",
    "    # pivot 먼저 정의!\n",
    "    _, pivot = load_monthly_data(data_path)\n",
    "    print(\"pivot columns:\", pivot.columns)\n",
    "    print(\"pivot shape:\", pivot.shape)\n",
    "    print(\"nonzero counts:\", [np.count_nonzero(pivot[col]) for col in pivot.columns])\n",
    "\n",
    "    sweep_log = []\n",
    "    # 그 다음 sweep 함수 실행!\n",
    "    top_candidates = sweep_thresholds_and_select_topN(pivot, thresholds, topN, min_nonzero=min_nonzero)\n",
    "    if not top_candidates:\n",
    "        raise ValueError(\"Sweep 후보가 없습니다. threshold 범위, 데이터 조건, 쌍 생성 결과를 점검하세요.\")\n",
    "    best = top_candidates[0]\n",
    "\n",
    "    pairs = find_comovement_pairs(\n",
    "        pivot, max_lag=6, min_nonzero=min_nonzero, corr_threshold=best[\"threshold\"]\n",
    "    )\n",
    "    train_df = build_training_data(pivot, pairs)\n",
    "    model, feature_cols = train_regression_model(train_df)\n",
    "    importances = model.feature_importances_\n",
    "    feat_names = feature_cols      # (혹은 required_cols, train_df.columns 등)\n",
    "    for name, score in sorted(zip(feat_names, importances), key=lambda x: -x[1]):\n",
    "        print(f\"[Importance] {name}: {score}\")\n",
    "    plot_feature_importance(model, feature_cols, topn=20)\n",
    "\n",
    "    top_feats = [name for name, score in sorted(zip(feat_names, importances), key=lambda x: -x[1])[:15]]\n",
    "    \n",
    "    pred_df = build_inference_features(pivot, pairs, forecast_month)\n",
    "    submission = create_submission(pairs, pred_df, pivot, model, feature_cols)\n",
    "    today = pd.Timestamp.today().strftime(\"%Y%m%d\")\n",
    "    output_path = f\"submission_rulelgbm_v5_th{int(best['threshold']*100)}_{today}.csv\"\n",
    "    submission.to_csv(output_path, index=False)\n",
    "    print(f\"{output_path} 저장 완료 (총 {len(submission)}개 pair)\")\n",
    "\n",
    "    sweep_log.append({\n",
    "        \"threshold\": th,\n",
    "        \"num_pairs\": len(pairs),\n",
    "        \"num_train\": len(train_df),\n",
    "        \"best_params\": model.get_params(),\n",
    "        # 필요시 RMSE 등 넣어도 됨\n",
    "    })\n",
    "    pd.DataFrame(sweep_log).to_csv(\"sweep_log_checkpoint.csv\", index=False) # 반복마다 log 저장\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
